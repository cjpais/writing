<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="../../static/main.css">
    <link rel="stylesheet" href="static/main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>Impact of Apple's M1 on the Semiconductor Industry</title>
  </head>

  <body class="container">
    <h1>Impact of Apple’s M1 on the Semiconductor Industry</h1>
<p>Apple’s M1 Changes Everything</p>
<ul>
<li>This title then begs the question, what is the state of the industry now (before M1)</li>
<li>What is the state after the M1. What has been shaken up Gamechanger</li>
</ul>
<p>Title’s in the form of questions?</p>
<p>transformative change?</p>
<p>Apple has shifted the balance of power with the release of the M1 powered Macs. Apple by releasing these M1 Macs is just begging for a response from the rest of the industry.</p>
<p>analyze the consumer space and the server space</p>
<p>Will be focusing just on how Apple’s decision to release ARM based Mac’s will force the rest of the industry to respond. I will not be digging into why Apple would move to ARM. That discussion will be saved for a future article.</p>
<p>Apple’s release of ARM powered Mac’s is flipping the industry on it’s head. The sheer amount of press around this release is quite telling. <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">The buzz on Twitter, HN, has been continuous</a>.</p>
<p>At this point we know they are <em><strong>fast</strong></em> with incredible battery life to boot.</p>
<p>These are fantastic things and these two factors will be the driving force for huge change in the industry. Consumer space and corporate space alike.</p>
<p>Did Apple force the industry’s hand to transition to ARM?</p>
<h2>Heterogeneous compute</h2>
<p>https://erik-engheim.medium.com/why-is-apples-m1-chip-so-fast-3262b158cba2 excellently written and want something similar to this, but maybe more opinion. opinion rooted in fact. or rather just opening up the room for discussion</p>
<p>probably want some pictures or something instead of pure text otherwise peoples brains will probably turn off or something since people arent good at having attention span (neither am i)</p>
<p>Nvidia can compete</p>
<h2>Consumer Side</h2>
<p>For the consumer side of things I think it’s quite simple. <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/#battery-life-is-insane">People are <em>stoked</em></a> to have a laptop that can last multiple days on battery.</p>
<p>This alone seems like it will drive the rest of the consumer market to follow Apple.</p>
<p>Given that other Windows laptops with ARM CPU’s have been released, why is it only now that it’s a big deal? The Surface Pro X has great battery life too</p>
<ul>
<li>apparently it serves a “small group of people” which Apple’s laptops definitely do not</li>
<li>apple serves everyone, people dont have much choice once their lineup goes all arm
<ul>
<li>which it certainly will</li>
</ul></li>
</ul>
<p>I feel like this is something like Apple dropping the headphone jack. At first the whole industry and consumers are bewildered by the move. Then sure enough the rest of the smartphone industry follows Apple and drops the headphone jack. Apple proved to the rest of the industry that you could remove the headphone jack, provide a better user experience, and ultimately make more money off consumers.</p>
<p>How do Microsoft, Intel, AMD, Qualcomm, NVidia respond to such a performant chip in a $700 package?</p>
<h2>Will ARM completely take over the industry?</h2>
<p>This seems unlikely in the near term. There is such a massive amount of code running on x86 machines that probably won’t be deprecated for a long time.</p>
<p>There may be a transition in ISA in the consumer space for sure, but the server space is a much much longer game to play.</p>
<p>ARM based</p>
<p>What if Microsoft doesn’t respond?</p>
<p>It seems to me this is quite unlikely.</p>
<p>Microsoft has been working with Qualcomm for years to have Windows on ARM. Laptops like the Surface Pro X have been released, but haven’t gained anywhere near the traction that the M1 powered Mac’s have.</p>
<p>One of the problems with the Surface Pro X is the price. Who is going to pay $1500 for a laptop that might not run your apps and has no cult following?</p>
<p>Within a very short period of time it’s become clear that Apple is able to get extraordinary performance and battery life out of these new M1 powered Mac’s. To have a laptop that can last 2/3 of a day is mindboggling today, but soon enough this will be seen as abysmal battery life.</p>
<h2>Server Side</h2>
<p>It’s strange to talk about servers and Apple in the same sentence. It seems very very unlikely that Apple will jump back into the server space. However, we are not talking about Apple in the server space. We are talking about how Apple’s impact on the consumer space will drive the server space to change.</p>
<p>The driving force behind change in the server world will be dominated by change in the consumer space. <a href="https://www.realworldtech.com/forum/?threadid=183440&amp;curpostid=183486">As Linus Torvalds recognizes</a>, people don’t want to develop at home on x86 and then deploy on ARM. It doesn’t make any sense. With Apple moving towards ARM, it only makes sense that some of the server market will start moving towards ARM as well. Especially as more and more developers move their home systems to something ARM based.</p>
<p><a href="https://insights.stackoverflow.com/survey/2020#technology-developers-primary-operating-systems">MacOS computers represent approximately 27.5% of the machines developers use</a>. This is a significant number. This large number will motivate people to cross compile their software if they weren’t already.</p>
<h2>How does the industry respond?</h2>
<p>What will happen if this is the case? How do Intel and AMD respond. Where does this leave other semiconductor manufactures, notably Nvidia and Qualcomm?</p>
<p>If you can accept the assumptions made about the spaces, now we can go ahead and analyze some of the main players in the semiconductor industry who will be directly affected by the release of the M1 Macs in the next couple of years.</p>
<p>To refresh what we’ve learned since the release is this.</p>
<h2>Quantifying</h2>
<p>Unfortunately this chart does a pretty terrible job of telling really what is going on.</p>
<table>
<thead>
<tr class="header">
<th>CPU</th>
<th>TDP</th>
<th>Measured Power (at adapter)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Apple M1</td>
<td>~22W<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></td>
<td>27.2W<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></td>
</tr>
<tr class="even">
<td>AMD Ryzen 4800U</td>
<td>15W (configurable to 25W)<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
<td>49.5W<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></td>
</tr>
<tr class="odd">
<td>AMD Ryzen 4900HS</td>
<td>35W<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></td>
<td>105W <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></td>
</tr>
<tr class="even">
<td>Intel 1065G7</td>
<td>15W (configurable to 25W)<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></td>
<td>35W<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>CPU</th>
<th>TDP</th>
<th>Max Power</th>
<th>Raw ST PERF</th>
<th>ST Perf/Watt</th>
<th>Raw MT Perf</th>
<th>MT Perf/Watt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Apple M1</td>
<td>~22W</td>
<td>31W</td>
<td>28.85</td>
<td>0.9306451613</td>
<td>38.71</td>
<td>1.248709677</td>
</tr>
<tr class="even">
<td>AMD Ryzen 4800U</td>
<td>15W</td>
<td>34.39W</td>
<td>25.14</td>
<td>0.7310264612</td>
<td>28.25</td>
<td>0.8214597267</td>
</tr>
<tr class="odd">
<td>Intel 1185G7</td>
<td>28W</td>
<td>51.92W</td>
<td>21.52</td>
<td>0.4144838213</td>
<td>25.87</td>
<td>0.4982665639</td>
</tr>
<tr class="even">
<td>AMD Ryzen 5800X</td>
<td>105W</td>
<td>140.1W</td>
<td>47.89</td>
<td>0.3418272662</td>
<td>52.1</td>
<td>0.3718772305</td>
</tr>
<tr class="odd">
<td>Intel 10900K</td>
<td>125W</td>
<td>251.6W</td>
<td>47.35</td>
<td>0.1881955485</td>
<td>48.59</td>
<td>0.1931240064</td>
</tr>
</tbody>
</table>
<h3>Singlethreaded performance equaling desktop CPU’s.</h3>
<p>Power Usage:</p>
<ul>
<li>Jury is still out (will wait for notebookcheck.net)]
<ul>
<li>Good comparison point https://www.notebookcheck.net/The-Ryzen-7-4800U-is-an-Absolute-Monster-Lenovo-Yoga-Slim-7-14-Laptop-Review.456068.0.html</li>
</ul></li>
<li>Uses half the power of the 4800U which is 15W TDP (default, configurable to 25)
<ul>
<li>https://www.notebookcheck.net/AMD-Ryzen-7-4800U-Laptop-Processor-Benchmarks-and-Specs.449937.0.html (49.5W)</li>
<li>https://www.notebookcheck.net/Apple-M1-Processor-Benchmarks-and-Specs.503613.0.html (27.2W)</li>
<li>Getting 36% better battery life, with 49.9Wh vs 61Wh
<ul>
<li>Lenovo has 22% larger battery, so it appears this approximates the raw power consumption seen.</li>
</ul></li>
</ul></li>
<li>Uses a quarter of the power of a Ryzen 4900HS (35W TDP, 105W Measured)</li>
<li>GPU consuming about 10 Watts when fully loaded
<ul>
<li>https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/3</li>
</ul></li>
</ul>
<p>My guess is the M1 powered laptops really come into a class of their own when you are doing intense tasks on the battery. There have been some benchmarks that seem to validate this. The combination of power efficiency and speed means a lot more can be done on the laptop.</p>
<p>CPU Speed:</p>
<ul>
<li>Single-Threaded</li>
<li>Multi-Threaded</li>
</ul>
<p>GPU:</p>
<ul>
<li><p>GPU in MBA competes with discrete GPUs</p>
<ul>
<li>Radeon Pro 560X, Nvidia MX350</li>
<li>https://www.notebookcheck.net/Apple-MacBook-Air-2020-M1-Benchmarks-Should-you-get-7-or-8-GPU-cores.506105.0.html</li>
<li></li>
</ul></li>
<li><p>Power comparison</p>
<ul>
<li>Power compared to package power
<ul>
<li>The fact that Apple is able to achieve this in a total device power consumption of 5W including the SoC, DRAM, and regulators, versus +21W (1185G7) and 49W (5950X) package power figures, without DRAM or regulation, is absolutely mind-blowing.
<ul>
<li>https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive/4</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Performance comparison</p>
<ul>
<li>Single threaded performance rivals desktop CPU’s. Mind blowing.
<ul>
<li>https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive/4</li>
</ul></li>
<li></li>
</ul></li>
</ul>
<h2>Why has ARM been struggling in the server space and how apple is going to change this</h2>
<p>Well in the server space there seems to be little incentive to swap over to ARM especially given the huge hassle of changing ISA’s. Clearly this is not simple and that’s why Apple has spent so much time to provide tools to get people swapped over cleanly.</p>
<p>That is the beauty of what they’ve done. According to the stackoverflow developer survey, about 27.5% of developers use Apple systems. As we see a huge developer population move to ARM based Mac’s surely the tooling will have to support ARM very well.</p>
<p>This is massive and will force a rethink of the server space. Even Linus didn’t believe this was going to happen anytime soon</p>
<blockquote>
<p>Some people think that “the cloud” means that the instruction set doesn’t matter. Develop at home, deploy in the cloud.</p>
<p>That’s bullshit. If you develop on x86, then you’re going to want to deploy on x86, because you’ll be able to run what you test “at home” (and by “at home” I don’t mean literally in your home, but in your work environment).</p>
<p>Which means that you’ll happily pay a bit more for x86 cloud hosting, simply because it matches what you can test on your own local setup, and the errors you get will translate better.</p>
<p>Which in turn means that cloud providers will end up making more money from their x86 side, which means that they’ll prioritize it, and any ARM offerings will be secondary and probably relegated to the mindless dregs (maybe front-end, maybe just static html, that kind of stuff).</p>
<p>Guys, do you really not understand why x86 took over the server market?</p>
<p>It wasn’t just all price. It was literally this “develop at home” issue. Thousands of small companies ended up having random small internal workloads where it was easy to just get a random whitebox PC and run some silly small thing on it yourself. Then as the workload expanded, it became a “real server”. And then once that thing expanded, suddenly it made a whole lot of sense to let somebody else manage the hardware and hosting, and the cloud took over.</p>
</blockquote>
<p>https://www.realworldtech.com/forum/?threadid=183440&amp;curpostid=183486</p>
<p>ARM is already crushing x86 in the server space, but is probably highly underutilized. https://www.anandtech.com/show/15578/cloud-clash-amazon-graviton2-arm-against-intel-and-amd/9</p>
<p>I would guess that Amazon is making boatloads on these CPU’s when compared to their Intel and AMD counterparts, due to the lower power consumption.</p>
<p>Thinking about the future of the server space it seems quite clear the benefits of moving to ARM. Some of the biggest problems in the server space are power and cooling. Given the constraints that ARM CPU’s have traditionally been in, they can fill this niche quite well.</p>
<p>It will take some time to see how much less power A</p>
<p>From the perspective of someone operating a datacenter, why would you not want to move to ARM if the software support is there and the customers are too? As a benefit you can squeeze over 2x the compute in the same area while keeping the same thermal and power envelope.</p>
<p>Apple has shown the performance of an ARM based CPU can compete with the big boys in desktop environments.</p>
<h2>My Interpretation in Context of the Questions</h2>
<p>Opposition:</p>
<ul>
<li>Begs the question, why do servers not currently use low power CPU’s?
<ul>
<li>What do the workloads look like?</li>
<li>How can we compare an m1 webserver?</li>
</ul></li>
<li>How can the m1 compete with desktop CPU’s then get crushed by laptop CPU’s?</li>
<li>ARM compatibility on Linux? How good is it and will Apple’s transition actually help here?</li>
</ul>
<p>Why the industry might want to move to ARM anyway. Or why there might be a push.</p>
<h2>LOTS OF COMPETITION IN THE SEMICONDUCTOR INDUSTRY</h2>
<p>Hard to say who will do well and who wont, but here’s my predictions</p>
<h2>AMD</h2>
<p>Looks like AMD still has a winner on its hands with the Zen3 arch. Very efficient and very fast. Doesn’t look like they are going to go away any time soon unless they falter on their next microarchs.</p>
<p>However they still have to compete with Apple, who seems to be progressing quite linearly when compared with the x86 space. (Well maybe intel wasn’t the bet comparison. I’ve made my own comparison based on Anandtech’s data)</p>
<p><img src="https://images.anandtech.com/doci/16226/perf-trajectory.png" /></p>
<p>The good think for AMD is it looks like they can compete with Apple in terms of performance per watt, or at least be relatively close to the benchmark set by Apple. However this is very short term thinking. I imagine the progression of ARM based microarchitectures are going to improve much more rapidly in terms of performance per watt. However this is based on pure speculation rather than facts or information.</p>
<p>They have put some ARM based CPU’s into the market according to: https://www.anandtech.com/show/15575/amperes-altra-80-core-n1-soc-for-hyperscalers-against-rome-and-xeon Opteron A1100 series in 2017.</p>
<p>This clearly was not a big success</p>
<p>Recently purchased Xilinx. I am not quite sure what to think about this now.</p>
<p>“Intel has stagnated itself out of the market, and has lost a major customer today. AMD has shown lots of progress lately, however it’ll be incredibly hard to catch up to Apple’s power efficiency. If Apple’s performance trajectory continues at this pace, the x86 performance crown might never be regained.”</p>
<h2>Intel</h2>
<p>At this moment Intel is in a tough spot. AMD has been starting to dominate Intel in the CPU space and seems to extending their lead with the Zen 2 microarchitecture. Beyond this they have been struggling to shrink their process nodes. Now they have lost Apple as a customer, and at the same time Apple is putting pressure on Intel and the entirety of the x86 space by threatening the server market.</p>
<p>Of course Intel is an interesting company that does a massive amount of R&amp;D which cannot be discounted.</p>
<h2>Qualcomm</h2>
<p>From QC perspective there is a huge opportunity with Apple moving to ARM. People see the performance and battery life they can get from a MBA. Beyond this Qualcomm has the value add of being able to add a modem for always connected PC’s. It is very dependent if people even want this in the first place. The cost of 4G/5G service is much more $/GB, however you don’t ever have to worry about wifi. I use my phone without worries much of these days and would be very nice to do the same for my computer.</p>
<p>Has a ways to catch up with Apple https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive/3</p>
<p><img src="https://images.anandtech.com/doci/16226/spec2006_A14.png" /></p>
<p>Looking at this picture we can clearly see that with the same amount of energy used (Joules) Apple nearly doubles Qualcomm’s performance.</p>
<p><img src="https://images.anandtech.com/graphs/graph16226/119329.png" /></p>
<p>Apple has clearly been playing a different game than Qualcomm. A response is very warranted. Could not be so good for QC.</p>
<p>However as we know, Apple now has shown ARM is viable for desktop PC’s for the masses. This will force pressure on Qualcomm and they have potential to deliver.</p>
<p>Qualcomm also has potential in the server space, which could help them compete in the consumer space as well.</p>
<h2>Nvidia</h2>
<p>Nvidia is in the most interesting spot out of all the major semiconductor manufacturers. They are already breaking into the server space with their GPU’s. They trying to purchase ARM Holdings. They have also been making ARM based CPU’s for some time with their Tegra line (however they have not seen much consumer success).</p>
<p>AI Accelerators. NVLink. Highly integrated SOC</p>
<p>NVLink with the CPU????</p>
<p>Jensen-Huang has specifically mentioned the like. https://www.tomshardware.com/news/jensen-huang-hints-at-nvidia-branded-arm-cpus</p>
<p>Remember NVidia is not new to building ARM processors. They have been doing so since the original Tegra APX 2500 in 2008. They have not been the most high profile SOC’s out there (given the mobile space is mostly dominated by Qualcomm/Samsung/Huawei). However the Nintendo Switch runs based on a Tegra X1 SOC.</p>
<p>It’s possible for Nvidia to come up with an extremely powerful and low power solution that could compete with Apple in a huge way. They have the GPU/TPU prowess and with bringing ARM on board could really be a force to be reckoned with in the consumer and server space.</p>
<p>The consumer space could benefit immensely from a deeply integrated CPU/GPU/GPGPU combo, leading to incredible performance and very low power. This could be perfect for the next generation of gaming laptops, or perhaps even better VR headsets or other AR devices.</p>
<p>One big stumbling block potential for NVidia is if they continue to remain very proprietary with their drivers and software. Most of the server industry runs on Linux, so deep support in Linux would be ideal for them.</p>
<p>The best case scenario for Nvidia is to completely dominate the server and consumer space with their own CPU/GPU/AI Accelerator combos.</p>
<h2>Amazon</h2>
<p>Amazon is ahead of the game. They have had ARM based EC2 instances for some time. Beyond that <a href="https://www.anandtech.com/show/15578/cloud-clash-amazon-graviton2-arm-against-intel-and-amd/9">it’s been proven they offer massive amounts of compute per $</a>.</p>
<p>I’d imagine that Amazon is making money hand over fist</p>
<p>It will take a while for the rest of the industry to catch up, but as more and more developers start building docker images for ARM, I suspect more and more ARM servers will be desired.</p>
<h2>Samsung and TSMC?</h2>
<h2>New Players</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Ampere_Computing">Ampere</a>
<ul>
<li>Nvidia is partnering with them as well. GPU-accelerated ARM servers partnership too……</li>
</ul></li>
<li>Nuvia</li>
<li>Marvell?</li>
</ul>
<h2>INTERCONNECTS?????!!!</h2>
<p>You would imagine companies like Mellanox and Infiband could stand to do extremely well here. If programs increasingly are becoming multithreaded and there are more CPU’s/Servers, you will need increasingly high performance interconnects. Anyhow this industry is not even close to going away any time soon. This is just another small boost to them. I don’t know enough about the specifics to really get into more detail.</p>
<h2>What about RISC-V??</h2>
<h2>CPU’s used by AWS</h2>
<ul>
<li>C4 - E5-2666 (v3 and v4)</li>
<li>C5n - Intel Platinum (3ghz)</li>
<li>C5a - AMD EPYC 7002</li>
<li>C5
<ul>
<li>Custom based on Cascade Lake</li>
<li>Xeon Platinum 8000</li>
</ul></li>
<li>M5
<ul>
<li>Platinum 8175M</li>
</ul></li>
</ul>
<p>LOL HOLY SHIT DIDNT THINK ABOUT THIS: “This might be one reason why Apples does so well in browser benchmarks (JavaScript numbers are floating-point doubles).” - https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive/2</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://www.notebookcheck.net/Apple-M1-Processor-Benchmarks-and-Specs.503613.0.html<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>https://www.amd.com/en/products/apu/amd-ryzen-7-4800u<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>https://www.notebookcheck.net/AMD-Ryzen-7-4800U-Laptop-Processor-Benchmarks-and-Specs.449937.0.html<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>https://www.amd.com/en/products/apu/amd-ryzen-9-4900hs<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>https://www.notebookcheck.net/AMD-Ryzen-9-4900HS-Processor-Benchmarks-and-Specs.454860.0.html<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Power was measured at the wall adapter as far as I can tell including the GPU (RTX 2060) which would increase overall power consumption<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>https://ark.intel.com/content/www/us/en/ark/products/196597/intel-core-i7-1065g7-processor-8m-cache-up-to-3-90-ghz.html<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>https://www.notebookcheck.net/Intel-Core-i7-1065G7-Laptop-Processor-Ice-Lake.423851.0.html<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

  </body>

</html>